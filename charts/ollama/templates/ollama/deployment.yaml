apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ollama.fullname" . }}
  labels:
    {{- include "ollama.labels" . | nindent 4 }}
spec:
  strategy:
    type: Recreate
  {{- if not .Values.ollama.autoscaling.enabled }}
  replicas: {{ .Values.ollama.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "ollama.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.ollama.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "ollama.labels" . | nindent 8 }}
        {{- with .Values.ollama.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      {{- with .Values.ollama.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "ollama.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.ollama.podSecurityContext | nindent 8 }}
      containers:
        - name: {{ .Chart.Name }}
          securityContext:
            {{- toYaml .Values.ollama.securityContext | nindent 12 }}
          image: "{{ .Values.ollama.image.repository }}:{{ .Values.ollama.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.ollama.image.pullPolicy }}
          ports:
            - name: http
              containerPort: {{ .Values.ollama.service.port }}
              protocol: TCP
          env:
          {{- range $key, $value := .Values.ollama.env }}
            - name: {{ printf "%s" $key | replace "." "_" | upper | quote }}
              value: {{ tpl $value $ | quote }}
          {{- end }}
          {{- if or .Values.ollama.ollama.gpu.enabled .Values.ollama.ollama.gpu.enable }}
            - name: PATH
              value: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
            - name: LD_LIBRARY_PATH
              value: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: compute,utility
          {{- end}}
          {{- if .Values.ollama.envFromSecret}}
          envFrom:
            - secretRef:
                name: {{.Values.ollama.envFromSecret}}
              {{- end }}
          {{- if .Values.ollama.resources }}
          resources:
            {{- $limits := default dict .Values.ollama.resources.limits }}
            {{- if or .Values.ollama.ollama.gpu.enabled .Values.ollama.ollama.gpu.enable }}
              {{- $gpuLimit := dict "nvidia.com/gpu" (.Values.ollama.ollama.gpu.number  | default 1) }}
              {{- $limits = merge $limits $gpuLimit }}
            {{- end }}
            {{- $ressources := merge .Values.ollama.resources (dict "limits" $limits) }}
            {{- toYaml $ressources | nindent 12 }}
          {{- end}}
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
          {{- with .Values.ollama.volumeMounts }}
            {{- toYaml . | nindent 12 }}
          {{- end }}
          {{- if .Values.ollama.livenessProbe.enabled }}
          livenessProbe:
            httpGet:
              path: {{ .Values.ollama.livenessProbe.path }}
              port: http
            initialDelaySeconds: {{ .Values.ollama.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.ollama.livenessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.ollama.livenessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.ollama.livenessProbe.successThreshold }}
            failureThreshold: {{ .Values.ollama.livenessProbe.failureThreshold }}
          {{- end }}
          {{- if .Values.ollama.readinessProbe.enabled }}
          readinessProbe:
            httpGet:
              path: {{ .Values.ollama.readinessProbe.path }}
              port: http
            initialDelaySeconds: {{ .Values.ollama.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.ollama.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.ollama.readinessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.ollama.readinessProbe.successThreshold }}
            failureThreshold: {{ .Values.ollama.readinessProbe.failureThreshold }}
          {{- end }}
      volumes:
        - name: ollama-data
          {{- if .Values.ollama.persistentVolume.enabled }}
          persistentVolumeClaim:
            claimName: {{ .Values.ollama.persistentVolume.existingClaim |  default (printf "%s" (include "ollama.fullname" .)) }}
          {{- else }}
          emptyDir: { }
          {{- end }}
        {{- with .Values.ollama.volumes }}
          {{- toYaml . | nindent 8 }}
        {{- end }}
      {{- with .Values.ollama.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.ollama.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- if or .Values.ollama.ollama.gpu.enabled .Values.ollama.tolerations }}
      tolerations:
        {{- if or .Values.ollama.ollama.gpu.enabled .Values.ollama.ollama.gpu.enable }}
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
        {{- end }}
        {{- with .Values.ollama.tolerations }}
          {{- toYaml . | nindent 8 }}
        {{- end }}
      {{- end }}