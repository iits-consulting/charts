global:
  ingress:
    enabled: true
    host:
    hosts:
      prometheus:
       host: "prometheus.{{.Values.global.ingress.host}}"
       path: "/"
      grafana:
        host: "grafana.{{.Values.global.ingress.host}}"
        path: "/"
      alertmanager:
        host: "alertmanager.{{.Values.global.ingress.host}}"
        path: "/"
    annotations:
      traefik.ingress.kubernetes.io/router.entrypoints: websecure
      traefik.ingress.kubernetes.io/router.tls: "true"
      traefik.ingress.kubernetes.io/router.middlewares: routing-oidc-forward-auth@kubernetescrd

prometheusStack:
  kubeProxy:
    enabled: false
  kubeScheduler:
    enabled: false
  kubelet:
    enabled: true
  nameOverride: prometheus-stack

  crds:
    enabled: false

  kubeControllerManager:
    enabled: false

  defaultRules:
    create: true
    disabled:
      KubeClientCertificateExpiration: true
      NodeClockNotSynchronising: true #CCE does not give access to that
      KubeletDown: true  #CCE does not give access to that
      InfoInhibitor: true #It is spamming
    rules:
      alertmanager: true
      etcd: true
      general: true
      k8s: true
      kubeApiserver: true
      kubeApiserverAvailability: true
      kubeApiserverError: true
      kubeApiserverSlos: true
      kubePrometheusGeneral: true
      kubePrometheusNodeAlerting: true
      kubePrometheusNodeRecording: true
      kubernetesAbsent: true
      kubernetesApps: true
      kubernetesResources: false #We need to customize the CPUThrottlingHigh Alert and increase the CPU to X; see also kubernetes-resources.yaml line 151
      kubernetesStorage: true
      kubernetesSystem: true
      kubeStateMetrics: true
      network: true
      node: true
      prometheus: true
      prometheusOperator: true
      time: true
  prometheus:
    prometheusSpec:
      externalUrl: "https://{{$.Values.global.ingress.hosts.prometheus.host}}{{$.Values.global.ingress.hosts.prometheus.path}}"
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      probeSelectorNilUsesHelmValues: false
      podMonitorSelector: null
      resources:
        requests:
          memory: "2255Mi"
          cpu: "60m"
      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes: [ "ReadWriteOnce" ]
            resources:
              requests:
                storage: 30G
  prometheusOperator:
    enabled: true
    tls:
      enabled: false
    admissionWebhooks:
      enabled: false
      patch:
        enabled: false
  grafana:
    serviceMonitor:
      path: "/metrics"
    # -- Required
    adminPassword:
    grafana.ini:
      server:
        root_url: "https://{{$.Values.global.ingress.hosts.grafana.host}}{{$.Values.global.ingress.hosts.grafana.path}}"
      auth:
        disable_login_form: false
      auth.basic:
        enabled: true
      security:
        disable_initial_admin_creation: false

  alertmanager:
    config:
      global:
        resolve_timeout: 5m
        slack_api_url: "http://myhost.local"
      route:
        group_by: [ 'job' ]
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        routes:
          - receiver: 'null'
            match:
              alertname: Watchdog
          - receiver: 'slack'
            continue: true
      receivers:
        - name: 'null'
        - name: 'slack'
          slack_configs:
            - channel: 'infrastructure'
              link_names: true
              send_resolved: true
              title_link: '{{ (index .Alerts 0).GeneratorURL }}'
              title: '{{ (index .Alerts 0).GeneratorURL | reReplaceAll "(.*)prometheus(.*)" "$1"}}  {{ (index .Alerts 0).Annotations.summary}}'
              text: >-
                {{ range .Alerts }}
                  *Description:* {{ .Annotations.description }}
                  *Details:*
                  {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
                  {{ end }}
                {{ end }}
      templates:
        - /etc/alertmanager/config/*.tmpl
    alertmanagerSpec:
      externalUrl: "https://{{$.Values.global.ingress.hosts.alertmanager.host}}{{$.Values.global.ingress.hosts.alertmanager.path}}"
      resources:
        requests:
          memory: "100Mi"
          cpu: "5m"

# Kyverno Policy Exception
policyException:
  enabled: true
